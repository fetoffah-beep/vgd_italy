{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Connected to spyder (Python 3.12.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c370543a",
   "metadata": {},
   "source": [
    "To implement the \"Batch\" or \"Tiled\" approach, you need to change your data access pattern. Instead of treating every 5x5 patch as an independent I/O request, you treat them as **sub-sections of a larger spatial block** that you load once and keep in memory.\n",
    "\n",
    "This is highly effective because loading one $256 \\times 256$ tile is often nearly as fast as loading one $5 \\times 5$ patch due to how disk headers and network protocols (like S3 or local filesystems) handle data \"bursts.\"\n",
    "\n",
    "### üèóÔ∏è The Strategy: Tile-and-Cache\n",
    "\n",
    "To make this work in a PyTorch `Dataset`, follow these three steps:\n",
    "\n",
    "#### 1\\. Group Points by Tile\n",
    "\n",
    "In your `__init__`, you must divide your geographic extent into a grid of large tiles (e.g., $256 \\times 256$ pixels). Assign every point in your metadata to a `tile_id`.\n",
    "\n",
    "```python\n",
    "# In __init__:\n",
    "# Assume resolution is 100m\n",
    "tile_size_px = 256\n",
    "res = 100 \n",
    "tile_size_m = tile_size_px * res\n",
    "\n",
    "# Calculate which tile each point belongs to\n",
    "self.metadata['tile_y'] = (self.metadata['northing'] // tile_size_m).astype(int)\n",
    "self.metadata['tile_x'] = (self.metadata['easting'] // tile_size_m).astype(int)\n",
    "self.metadata['tile_id'] = self.metadata['tile_y'].astype(str) + \"_\" + self.metadata['tile_x'].astype(str)\n",
    "\n",
    "# IMPORTANT: Sort metadata by tile_id so sequential __getitem__ calls hit the same tile\n",
    "self.metadata = self.metadata.sort_values('tile_id').reset_index(drop=True)\n",
    "```\n",
    "\n",
    "#### 2\\. Implement the Internal Cache\n",
    "\n",
    "In `__getitem__`, you check if the requested point falls within the \"Active Tile\" already in memory. If it doesn't, you fetch the new large tile.\n",
    "\n",
    "```python\n",
    "class VGDDataset(Dataset):\n",
    "    def __init__(self, ...):\n",
    "        # ... (other init code) ...\n",
    "        self.current_tile_id = None\n",
    "        self.tile_cache = {} # Stores the 256x256 data in RAM\n",
    "\n",
    "    def __getitem__(self, item_idx):\n",
    "        entry = self.metadata.iloc[item_idx]\n",
    "        target_tile = entry['tile_id']\n",
    "\n",
    "        # Check if we need to load a new tile\n",
    "        if target_tile != self.current_tile_id:\n",
    "            self._load_tile_to_cache(entry['tile_y'], entry['tile_x'])\n",
    "            self.current_tile_id = target_tile\n",
    "\n",
    "        # Now, instead of going to disk/Dask, slice from self.tile_cache\n",
    "        # px, py are local offsets within the 256x256 tile\n",
    "        px = int((entry['easting'] % tile_size_m) // res)\n",
    "        py = int((entry['northing'] % tile_size_m) // res)\n",
    "        \n",
    "        # Fast slice from RAM (NumPy/Torch)\n",
    "        patch = self.tile_cache['dynamic'][:, py-2:py+3, px-2:px+3]\n",
    "        \n",
    "        return patch # + static/target/etc\n",
    "```\n",
    "\n",
    "#### 3\\. The Tile Loader\n",
    "\n",
    "This function uses Xarray/Dask to pull one large chunk. Because it happens once every \\~100-500 samples (depending on point density), the Dask scheduler overhead becomes negligible.\n",
    "\n",
    "```python\n",
    "def _load_tile_to_cache(self, tile_y, tile_x):\n",
    "    # Define bounds for the 256x256 area\n",
    "    y_min = tile_y * tile_size_m\n",
    "    y_max = y_min + tile_size_m\n",
    "    x_min = tile_x * tile_size_m\n",
    "    x_max = x_min + tile_size_m\n",
    "    \n",
    "    # Single Xarray call for the whole block\n",
    "    # Use .load() to bring it into actual RAM\n",
    "    tile_ds = self.dynamic_data.sel(\n",
    "        northing=slice(y_max, y_min), \n",
    "        easting=slice(x_min, x_max)\n",
    "    ).load() \n",
    "    \n",
    "    self.tile_cache['dynamic'] = tile_ds['variable_name'].values\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### ‚ö†Ô∏è Critical Note on PyTorch Multi-processing\n",
    "\n",
    "If you use `num_workers > 0` in your `DataLoader`, each worker process will have its own `tile_cache`.\n",
    "\n",
    "  * **The Problem:** If Worker 1 gets Sample A (Tile 1) and Worker 2 gets Sample B (also Tile 1), they both load the same tile, wasting RAM.\n",
    "  * **The Fix:** PyTorch fills batches sequentially. Since we **sorted** the metadata by `tile_id` in step 1, Worker 1 will likely get a long sequence of samples all from Tile 1, while Worker 2 gets a sequence from Tile 2. This keeps the cache hit-rate very high.\n",
    "\n",
    "### üöÄ Why this fixes your Dask Dashboard\n",
    "\n",
    "Looking at your previous image, the \"Task Stream\" was full of tiny slivers. With this tiled approach:\n",
    "\n",
    "1.  Instead of 10,000 tiny `getitem` tasks, Dask will see **one large task** (the 256x256 read).\n",
    "2.  The \"white space\" (scheduler overhead) disappears because the CPU is busy slicing from RAM for the next 500 samples without asking Dask for anything.\n",
    "\n",
    "**Would you like me to help you calculate the exact pixel-offset math for your specific EPSG:3035 coordinate system?**\n",
    "\n",
    "\n",
    "You are absolutely right. Shuffling is the \"enemy\" of caching. If your `DataLoader` has `shuffle=True`, it will request a point in Italy, then a point in Sweden, then another in Italy, forcing your code to reload massive files constantly.\n",
    "\n",
    "To fix this while keeping your training effective, you have two main strategies: **Custom Batch Sampling** or a **Multi-Tile LRU Cache**.\n",
    "\n",
    "-----\n",
    "\n",
    "### Strategy 1: The \"Geographic\" Batch Sampler (Most Efficient)\n",
    "\n",
    "Instead of shuffling every single point globally, you shuffle **by tiles**. This ensures that one batch of data (e.g., 32 samples) all comes from the same $256 \\times 256$ area. This is a common practice in geospatial deep learning.\n",
    "\n",
    "**How it works:**\n",
    "\n",
    "1.  Group all metadata indices by their `tile_id`.\n",
    "2.  Shuffle the list of tiles.\n",
    "3.  For each tile, shuffle the points within it.\n",
    "4.  Feed these sequences to the trainer.\n",
    "\n",
    "<!-- end list -->\n",
    "\n",
    "```python\n",
    "from torch.utils.data import Sampler\n",
    "import random\n",
    "\n",
    "class TileBatchSampler(Sampler):\n",
    "    def __init__(self, metadata, batch_size):\n",
    "        self.batch_size = batch_size\n",
    "        # Group indices by tile_id: { 'tile_1': [index1, index5...], 'tile_2': [index2, index3...] }\n",
    "        self.tile_groups = metadata.groupby('tile_id').indices\n",
    "        self.tile_ids = list(self.tile_groups.keys())\n",
    "\n",
    "    def __iter__(self):\n",
    "        # 1. Shuffle the order of the tiles themselves\n",
    "        random.shuffle(self.tile_ids)\n",
    "        \n",
    "        batch = []\n",
    "        for tid in self.tile_ids:\n",
    "            indices = self.tile_groups[tid].tolist()\n",
    "            # 2. Shuffle points within this specific tile\n",
    "            random.shuffle(indices)\n",
    "            \n",
    "            for idx in indices:\n",
    "                batch.append(idx)\n",
    "                if len(batch) == self.batch_size:\n",
    "                    yield batch\n",
    "                    batch = []\n",
    "        if len(batch) > 0:\n",
    "            yield batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tile_groups) # Roughly\n",
    "```\n",
    "\n",
    "**Usage:**\n",
    "\n",
    "```python\n",
    "sampler = TileBatchSampler(dataset.metadata, batch_size=32)\n",
    "loader = DataLoader(dataset, batch_sampler=sampler) # Do NOT set shuffle=True here\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### Strategy 2: The Multi-Tile LRU Cache (Least Code Change)\n",
    "\n",
    "If you must have global shuffling (picking any point in the country at any time), you need a **Least Recently Used (LRU) Cache**. Instead of keeping just one tile in memory, you keep the last 10 or 20.\n",
    "\n",
    "Even with a global shuffle, if your points are somewhat dense, there is a high statistical probability that a \"random\" index will fall into one of the 20 tiles you already have in RAM.\n",
    "\n",
    "```python\n",
    "from collections import OrderedDict\n",
    "\n",
    "class VGDDataset(Dataset):\n",
    "    def __init__(self, ...):\n",
    "        self.cache = OrderedDict()\n",
    "        self.max_cache_size = 15 # Adjust based on your RAM (e.g., 15 tiles of 256x256)\n",
    "\n",
    "    def _get_tile(self, tile_id, tile_y, tile_x):\n",
    "        if tile_id in self.cache:\n",
    "            # Move to end (mark as recently used)\n",
    "            self.cache.move_to_end(tile_id)\n",
    "            return self.cache[tile_id]\n",
    "        \n",
    "        # Load new tile if not in cache\n",
    "        tile_data = self._load_from_disk(tile_y, tile_x)\n",
    "        \n",
    "        # Add to cache\n",
    "        self.cache[tile_id] = tile_data\n",
    "        \n",
    "        # If cache too big, remove oldest\n",
    "        if len(self.cache) > self.max_cache_size:\n",
    "            self.cache.popitem(last=False)\n",
    "            \n",
    "        return tile_data\n",
    "```\n",
    "\n",
    "-----\n",
    "\n",
    "### Which one should you choose?\n",
    "\n",
    "| Feature | Geographic Batch Sampler | LRU Cache |\n",
    "| :--- | :--- | :--- |\n",
    "| **Speed** | üöÄ **Fastest**. Almost zero disk I/O during a batch. | üê¢ **Moderate**. Depends on point density. |\n",
    "| **Randomness** | Good (shuffled tiles + shuffled points). | Perfect (global shuffle). |\n",
    "| **RAM Usage** | Low (only needs 1 tile per worker). | High (needs $N$ tiles per worker). |\n",
    "| **Implementation** | Requires a custom Sampler. | Easy logic inside Dataset. |\n",
    "\n",
    "### üí° Pro Tip for Geospatial ML\n",
    "\n",
    "Most researchers use **Strategy 1**. Total global randomness is rarely necessary for convergence in Earth Observation models. As long as your batches move from a \"Forest\" tile to a \"City\" tile to a \"Desert\" tile, the model generalizes perfectly well. The 10x speedup usually outweighs the minor loss in shuffle entropy.\n",
    "\n",
    "**Would you like me to refine the pixel-coordinate math so the 5x5 slice is always perfectly centered within these tiles?**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d26e810c",
   "metadata": {},
   "source": [
    "1. The Critical Bottlenecks\n",
    "#1: Static Data Sampling (Lines 275‚Äì276)\n",
    "Time: 8.09e+10 (The largest single value in the report)\n",
    "\n",
    "The Issue: ds.where(ds.notnull()).sel(...)\n",
    "\n",
    "Why it's slow: You are calling .where(ds.notnull()) inside the __getitem__ method. This creates a masked copy of the entire dataset 17,830 times (once for every static variable for every sample). This is likely triggering expensive disk reads or computation of the mask repeatedly.\n",
    "\n",
    "#2: Seismic Data Indexing (Line 228)\n",
    "Time: 7.34e+09\n",
    "\n",
    "The Issue: ds[var_name].isel(...).sel(...)\n",
    "\n",
    "Why it's slow: Using .isel() and .sel() with xr.DataArray objects as indices for every hit is computationally expensive in xarray, especially if the data isn't loaded into memory.\n",
    "\n",
    "#3: Metadata Access (Line 193)\n",
    "Time: 4.56e+07\n",
    "\n",
    "The Issue: entry = self.metadata.iloc[idx]\n",
    "\n",
    "Why it's slow: While smaller than the xarray hits, iloc on a Pandas DataFrame is notoriously slow when called millions of times in a DataLoader loop.\n",
    "\n",
    "2. Immediate Optimization Strategies\n",
    "To speed this up significantly (potentially by 10x or more), consider these changes:\n",
    "\n",
    "A. Pre-Process/Load into Memory\n",
    "The biggest win is avoiding xarray overhead during training.\n",
    "\n",
    "Load Static Data: If your static data fits in RAM, call .load() on your static datasets before passing them to the Dataset class.\n",
    "\n",
    "Remove .where(notnull()): Instead of checking for NaNs on every __getitem__ call, handle the NaNs once during initialization or use a simpler np.nan_to_num after converting to a numpy array.\n",
    "\n",
    "B. Convert to NumPy/Torch Early\n",
    "Xarray's .sel() and .isel() provide great flexibility but have high overhead for deep learning.\n",
    "\n",
    "Convert your coordinates (lat/lon) to integer indices once during __init__.\n",
    "\n",
    "Inside __getitem__, use standard NumPy-style slicing on the underlying .values or .data array rather than using labeled indexing.\n",
    "\n",
    "C. Optimize Metadata Access\n",
    "Convert your self.metadata DataFrame into a dictionary of arrays or a NumPy structured array in __init__.\n",
    "\n",
    "Example:\n",
    "\n",
    "D. Avoid Redundant Conversions\n",
    "Line 256 & 299: You are calling torch.tensor(sampled) inside a loop. If possible, convert the entire dataset to a Torch tensor or a memory-mapped NumPy array once so you only perform a slice operation during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9651c6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "from rasterio.features import rasterize\n",
    "from rasterio.transform import from_bounds\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e796e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "lithology = gpd.read_file(r\"C:\\Users\\gmfet\\Desktop\\predictors\\lithology\\litology_italy.gpkg\")\n",
    "output_path = r'C:\\Users\\gmfet\\Desktop\\collaboration_with_Awais\\lithology.tif'\n",
    "\n",
    "# Get the bounds of the file\n",
    "xmin, ymin, xmax, ymax = lithology.total_bounds\n",
    "res = 0.001  # pixel size\n",
    "\n",
    "# width = int((xmax - xmin) / res)\n",
    "height = int((ymax - ymin) / res)\n",
    "width = height\n",
    "transform = from_bounds(xmin, ymin, xmax, ymax, width, height)\n",
    "\n",
    "shapes = ((geom, value) for geom, value in zip(lithology.geometry, lithology[\"cat\"]))\n",
    "\n",
    "with rasterio.open(output_path, 'w', driver='GTiff', width=width, height=height, count=1, crs=lithology.crs, transform=transform, dtype='uint8') as geo_pckg:\n",
    "    geo_pckg.write(rasterize(shapes, out_shape=(height, width), fill=0, transform=transform, dtype='uint8'), 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48d98896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Geographic 2D CRS: EPSG:4326>\n",
       "Name: WGS 84\n",
       "Axis Info [ellipsoidal]:\n",
       "- Lat[north]: Geodetic latitude (degree)\n",
       "- Lon[east]: Geodetic longitude (degree)\n",
       "Area of Use:\n",
       "- name: World.\n",
       "- bounds: (-180.0, -90.0, 180.0, 90.0)\n",
       "Datum: World Geodetic System 1984 ensemble\n",
       "- Ellipsoid: WGS 84\n",
       "- Prime Meridian: Greenwich"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# italy shapefile \n",
    "shp_path = r\"C:\\Users\\gmfet\\vgd_italy\\italy_aoi\\gadm41_ITA_0.shp\"\n",
    "\n",
    "shp_file = gpd.read_file(shp_path)\n",
    "\n",
    "shp_file.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd17025",
   "metadata": {},
   "source": [
    "## Static features\n",
    "Save the categorical variables as uint8 dtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513eb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "\n",
    "\n",
    "filepath = r'C:\\Users\\gmfet\\vgd_italy\\regression\\original_data'\n",
    "\n",
    "file_list = os.listdir(filepath)\n",
    "for file in file_list:\n",
    "    if file.endswith('.tif'):\n",
    "        engine='rasterio'\n",
    "    elif file.endswith('.nc'):\n",
    "        engine = 'h5netcdf'\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    print(file)\n",
    "    \n",
    "    with xr.open_dataset(os.path.join(filepath, file), engine=engine) as data_ds:\n",
    "        rename_dict = {'x': 'longitude', 'y': 'latitude', 'lon': 'longitude', 'lat': 'latitude', 'band':'time'}\n",
    "        data_ds = data_ds.rename({k: v for k, v in rename_dict.items() if k in data_ds.dims})\n",
    "        print(data_ds.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09e3bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with xr.open_dataset(r\"C:\\Users\\gmfet\\vgd_italy\\regression\\original_data\\genua.nc\", engine='netcdf4') as ds:\n",
    "    print(ds.chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2081a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['ssm'].sel(time='2022-10-01').plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c4b2c906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset> Size: 104MB\n",
      "Dimensions:  (lon: 7200, lat: 3600)\n",
      "Coordinates:\n",
      "  * lon      (lon) float64 58kB -180.0 -179.9 -179.9 ... 179.9 179.9 180.0\n",
      "  * lat      (lat) float64 29kB 89.97 89.92 89.88 89.82 ... -89.88 -89.92 -89.97\n",
      "Data variables:\n",
      "    crs      int32 4B ...\n",
      "    Band1    (lat, lon) float32 104MB dask.array<chunksize=(3600, 7200), meta=np.ndarray>\n",
      "Attributes:\n",
      "    CDI:                        Climate Data Interface version 1.9.8 (https:/...\n",
      "    Conventions:                CF-1.5\n",
      "    history:                    Wed Dec 16 16:42:50 2020: cdo -mulc,10. ksat3...\n",
      "    GDAL_AREA_OR_POINT:         Area\n",
      "    GDAL:                       GDAL 3.0.4, released 2020/01/28\n",
      "    history_of_appended_files:  Fri Dec 11 16:53:00 2020: Appended file /huge...\n",
      "    NCO:                        netCDF Operators version 4.9.2 (Homepage = ht...\n",
      "    CDO:                        Climate Data Operators version 1.9.8 (https:/...\n"
     ]
    }
   ],
   "source": [
    "# with rxr.open_rasterio(r\"C:\\Users\\gmfet\\Desktop\\predictors\\LULC\\*.tif\", chunks=1000) as ds:\n",
    "#     ds\n",
    "with xr.open_mfdataset(r\"C:\\Users\\gmfet\\vgd_italy\\regression\\original_data\\ksat.nc\", engine='netcdf4') as ds:\n",
    "    print(ds)\n",
    "    ds = ds.rio.write_crs(\"EPSG:4326\", inplace=False)\n",
    "\n",
    "\n",
    "    # ds['band_data'] = ds['band_data'].rio.write_nodata(np.nan)\n",
    "    # ds = ds.astype('float32')\n",
    "    # ds = ds.rio.clip(shp_file.geometry, shp_file.crs, drop=True, all_touched=True)\n",
    "    \n",
    "    data_attrs = ds.attrs.copy()\n",
    "    coord_attrs = {c: ds[c].attrs.copy() for c in ds.coords}\n",
    "    # ds = ds.squeeze(\"band\", drop=True)\n",
    "    # # # ds = ds.drop_vars(\"spatial_ref\")\n",
    "    ds = ds.rename({\"lon\": \"longitude\", \"lat\": \"latitude\", 'Band1': 'ksat'})\n",
    "    ds = ds.chunk({'latitude': 256, 'longitude': 256})\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    # ds = ds.rename({\"x\": \"longitude\", \"y\": \"latitude\", 'band': 'time', 'band_data': 'drought_code'})\n",
    "    # ds['time'] = pd.date_range('2017-01-01', periods=ds.sizes['time'], freq='D')\n",
    "    # ds = ds.chunk({'time': -1})\n",
    "    # ds = ds.interpolate_na(\n",
    "    #     dim=\"time\", \n",
    "    #     method=\"polynomial\", \n",
    "    #     order=3,\n",
    "    #     fill_value=\"extrapolate\"\n",
    "        \n",
    "    # )\n",
    "\n",
    "    # ds = ds.chunk({'time': -1, 'latitude': 256, 'longitude': 256})\n",
    "\n",
    "    # # # # # # ds = ds.to_dataset(name='clay_content')\n",
    "    ds.attrs.update(data_attrs)\n",
    "    ds = ds.astype(\"float32\")\n",
    "\n",
    "    # restore coordinate attributes\n",
    "    for c in [\"longitude\", \"latitude\"]:\n",
    "        if c in coord_attrs:\n",
    "            ds[c].attrs.update(coord_attrs[c])\n",
    "\n",
    "    # # # ds = ds.dropna('latitude')\n",
    "\n",
    "    # # # ds = ds.rio.clip(shp_file.geometry, shp_file.crs, drop=True, all_touched=True)\n",
    "            \n",
    "    ds.to_netcdf(\"ksat.nc\", engine=\"h5netcdf\", encoding= {'ksat': {\"dtype\": \"float32\", \"zlib\": True, \"complevel\": 0, \"compression\": \"gzip\", \"compression_opts\": 0}})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509a3152",
   "metadata": {},
   "source": [
    "## Dynamic features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fa0158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with rxr.open_rasterio(r\"C:\\Users\\gmfet\\Desktop\\predictors\\LULC\\*.tif\", chunks=1000) as ds:\n",
    "#     ds\n",
    "# from dask.distributed import Client\n",
    "# client = Client() # This will give you a link to a dashboard (usually http://localhost:8787)\n",
    "\n",
    "encoding = {\n",
    "    \"temperature\": {\n",
    "        \"dtype\": \"float32\",        # Store as 16-bit integers\n",
    "        \"scale_factor\": 0.01,   # Preservation of 2 decimal places\n",
    "        # \"_FillValue\": -9999,    # Map NaNs to -9999\n",
    "        \"zlib\": True,           # Enable compression\n",
    "        \"complevel\": 0,         # Moderate compression level\n",
    "        # \"shuffle\": True,        # Better compression efficiency\n",
    "        # \"chunksizes\": (1, 180, 360) # Optimize for time-series access\n",
    "    }\n",
    "}\n",
    "\n",
    "# ds.to_netcdf(\"output.nc\", encoding=encoding)\n",
    "with xr.open_mfdataset(r\"C:\\Users\\gmfet\\vgd_italy\\data\\dynamic\\temperature.tif\", engine='rasterio') as ds:\n",
    "    ds\n",
    "    ds['band_data'] = ds['band_data'].rio.write_nodata(np.nan)\n",
    "    # ds = ds.chunk({'x': 1024, 'y': 1024})\n",
    "    ds = ds.astype('float32')\n",
    "    # # # # # ds = ds.rio.clip(shp_file.geometry, shp_file.crs, drop=True, all_touched=True)\n",
    "    \n",
    "    # ds = ds.fillna(0).astype(\"float32\")\n",
    "    data_attrs = ds.attrs.copy()\n",
    "    coord_attrs = {c: ds[c].attrs.copy() for c in ds.coords}\n",
    "    # # # ds = ds.drop_vars(\"spatial_ref\")\n",
    "    ds = ds.rename({\"x\": \"longitude\", \"y\": \"latitude\", 'band': 'time', 'band_data': 'drought_code'})\n",
    "    ds['time'] = pd.date_range('2017-01-01', periods=ds.sizes['time'], freq='D')\n",
    "    # ds = ds.chunk({'longitude': -1, 'latitude': 1024, 'time': 512})\n",
    "\n",
    "    # ds = ds.interpolate_na(\n",
    "    #     dim=\"longitude\", \n",
    "    #     method=\"linear\", \n",
    "    #     fill_value=\"extrapolate\"\n",
    "        \n",
    "    # )\n",
    "\n",
    "    ds = ds.chunk({'time': -1, 'latitude': 1024, 'longitude': 1024,})\n",
    "\n",
    "    # ds = ds.interpolate_na(\n",
    "    #     dim=\"time\", \n",
    "    #     method=\"linear\", \n",
    "    #     fill_value=\"extrapolate\"\n",
    "        \n",
    "    # )\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # # # # # # # ds = ds.to_dataset(name='bulk_density')\n",
    "    ds.attrs.update(data_attrs)\n",
    "    ds = ds.astype(\"float32\")\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # restore coordinate attributes\n",
    "    for c in [\"longitude\", \"latitude\"]:\n",
    "        if c in coord_attrs:\n",
    "            ds[c].attrs.update(coord_attrs[c])\n",
    "\n",
    "    # # # # ds = ds.dropna('latitude')\n",
    "\n",
    "    # # # # ds = ds.rio.clip(shp_file.geometry, shp_file.crs, drop=True, all_touched=True)\n",
    "    \n",
    "    ds.to_netcdf(\"temperature.nc\", engine=\"h5netcdf\", encoding= encoding)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42575f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ds = ds.astype(\"uint8\")\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d95e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['temperature'].sel(time='2018-08-01').plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63609e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.unique(ds['drought_code'].sel(time='2017-01-01').values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2e7d22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spyder",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
