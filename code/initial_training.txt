Epoch [1/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [2/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [3/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [4/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [5/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [6/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [7/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [8/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [9/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [10/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [11/100], Training Loss: 8.9892, Validation Loss: 8.9893
Epoch [12/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [13/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [14/100], Training Loss: 8.9896, Validation Loss: 8.9893
Epoch [15/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [16/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [17/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [18/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [19/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [20/100], Training Loss: 8.9891, Validation Loss: 8.9893
Epoch [21/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [22/100], Training Loss: 8.9891, Validation Loss: 8.9893
Epoch [23/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [24/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [25/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [26/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [27/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [28/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [29/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [30/100], Training Loss: 8.9897, Validation Loss: 8.9893
Epoch [31/100], Training Loss: 8.9890, Validation Loss: 8.9893
Epoch [32/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [33/100], Training Loss: 8.9892, Validation Loss: 8.9893
Epoch [34/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [35/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [36/100], Training Loss: 8.9891, Validation Loss: 8.9893
Epoch [37/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [38/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [39/100], Training Loss: 8.9892, Validation Loss: 8.9893
Epoch [40/100], Training Loss: 8.9892, Validation Loss: 8.9893
Epoch [41/100], Training Loss: 8.9892, Validation Loss: 8.9893
Epoch [42/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [43/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [44/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [45/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [46/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [47/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [48/100], Training Loss: 8.9891, Validation Loss: 8.9893
Epoch [49/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [50/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [51/100], Training Loss: 8.9892, Validation Loss: 8.9893
Epoch [52/100], Training Loss: 8.9896, Validation Loss: 8.9893
Epoch [53/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [54/100], Training Loss: 8.9896, Validation Loss: 8.9893
Epoch [55/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [56/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [57/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [58/100], Training Loss: 8.9891, Validation Loss: 8.9893
Epoch [59/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [60/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [61/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [62/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [63/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [64/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [65/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [66/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [67/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [68/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [69/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [70/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [71/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [72/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [73/100], Training Loss: 8.9892, Validation Loss: 8.9893
Epoch [74/100], Training Loss: 8.9891, Validation Loss: 8.9893
Epoch [75/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [76/100], Training Loss: 8.9890, Validation Loss: 8.9893
Epoch [77/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [78/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [79/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [80/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [81/100], Training Loss: 8.9896, Validation Loss: 8.9893
Epoch [82/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [83/100], Training Loss: 8.9892, Validation Loss: 8.9893
Epoch [84/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [85/100], Training Loss: 8.9896, Validation Loss: 8.9893
Epoch [86/100], Training Loss: 8.9890, Validation Loss: 8.9893
Epoch [87/100], Training Loss: 8.9892, Validation Loss: 8.9893
Epoch [88/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [89/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [90/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [91/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [92/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [93/100], Training Loss: 8.9896, Validation Loss: 8.9893
Epoch [94/100], Training Loss: 8.9894, Validation Loss: 8.9893
Epoch [95/100], Training Loss: 8.9895, Validation Loss: 8.9893
Epoch [96/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [97/100], Training Loss: 8.9892, Validation Loss: 8.9893
Epoch [98/100], Training Loss: 8.9893, Validation Loss: 8.9893
Epoch [99/100], Training Loss: 8.9892, Validation Loss: 8.9893
Epoch [100/100], Training Loss: 8.9893, Validation Loss: 8.9893
Training complete. Evaluate the model on the test set.
Out[5]: 
VGDModel(
  (lstm): LSTM(1, 64, num_layers=2, batch_first=True, dropout=0.2)
  (fc): Linear(in_features=64, out_features=1, bias=True)
)
